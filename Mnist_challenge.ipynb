{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadDataset(path,Train_size,Val_size,Test_size,batch_,Shuffle):\n",
    "\n",
    "    \n",
    "    _transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.Resize((img_Resize,img_Resize)),transforms.ToTensor(),\n",
    "                                       transforms.Normalize(0.1307,0.3081)])\n",
    "     \n",
    "    data_train = datasets.ImageFolder((data_dir + '/' + 'train') , transform=_transforms)\n",
    "    data_test=datasets.ImageFolder((data_dir+'/'+'test'), transform=_transforms)\n",
    "    \n",
    "    train_data, val_data = torch.utils.data.random_split(data_train, [Train_size, Val_size])\n",
    "\n",
    "    test_size=list(range(0, Test_size))\n",
    "    \n",
    "\n",
    "    test_data=torch.utils.data.Subset(data_test,test_size)\n",
    "    \n",
    "    print(len(train_data))\n",
    "    print(len(val_data))\n",
    "    print(len(test_data))\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_,shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_,shuffle=True)\n",
    "        \n",
    "    return train_loader,val_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_network(no_of_layers,input_dim,neurons_per_layer,droupout):\n",
    "    a=input_dim\n",
    "    b=neurons_per_layer[-1]\n",
    "    c=neurons_per_layer\n",
    "    d=droupout\n",
    "    \n",
    "    return a,b,c,d\n",
    "\n",
    "A,B,C,D=init_network(2, 784, [100, 50,10], 0.1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=A, output_dim=B, hidden_dim=C,droup_out=D):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        current_dim = input_dim\n",
    "        self.layers = nn.ModuleList()\n",
    "        for hdim in hidden_dim:\n",
    "            if(hdim==hidden_dim[-1]):\n",
    "                self.layers.append(nn.Dropout(droup_out))\n",
    "                self.layers.append(nn.Linear(current_dim, hdim))\n",
    "                current_dim = hdim\n",
    "                \n",
    "            else:\n",
    "                self.layers.append(nn.Linear(current_dim, hdim))\n",
    "                current_dim = hdim\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.leaky_relu(layer(x))\n",
    "        out = F.softmax(self.layers[-1](x))\n",
    "        return out   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(model):\n",
    "    torch.save(model.state_dict(), \"weights.pth\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net, train_loader, val_loader ,training_epochs, loss_func, optimizer):\n",
    "    \n",
    "    print(net)\n",
    "    train_loss_array=[]\n",
    "    train_loss_epoch=[]\n",
    "    train_accuracy_epoch=[]\n",
    "    val_loss_array=[]\n",
    "    val_loss_epoch=[]\n",
    "    val_accuracy_epoch=[]\n",
    "    criterion=loss_func \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        net.train()\n",
    "        correct = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)        \n",
    "            data = data.view(-1, img_Resize*img_Resize*1)\n",
    "            optimizer.zero_grad()\n",
    "            net_out = net(data)\n",
    "            pred = net_out.data.max(1)[1] \n",
    "            loss = criterion(net_out, target)\n",
    "            correct += pred.eq(target.data).sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                               100. * batch_idx / len(train_loader), loss.item()))\n",
    "                train_loss_array.append(loss.item())\n",
    "            \n",
    "        train_accuracy_=float(100 * correct / len(train_loader.dataset))\n",
    "        train_accuracy_epoch.append(train_accuracy_)\n",
    "        epoch_loss=np.mean(train_loss_array)\n",
    "        train_loss_array=[]\n",
    "        train_loss_epoch.append(epoch_loss)\n",
    "        print(train_loss_epoch)\n",
    "        print(train_accuracy_epoch)\n",
    "\n",
    "        correct=0\n",
    "        criterion=loss_func\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(val_loader):\n",
    "                data, target = Variable(data), Variable(target)\n",
    "                data, target = data.to(device), target.to(device)        \n",
    "                data = data.view(-1, img_Resize*img_Resize*1)\n",
    "                net_out = net(data)\n",
    "                pred = net_out.data.max(1)[1]\n",
    "    \n",
    "                loss = criterion(net_out, target)\n",
    "                correct += pred.eq(target.data).sum()\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print('Val Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                            epoch, batch_idx * len(data), len(val_loader.dataset),\n",
    "                                   100. * batch_idx / len(val_loader), loss.item()))\n",
    "                    val_loss_array.append(loss.item())\n",
    "                \n",
    "            val_accuracy_=float(100 * correct / len(val_loader.dataset))\n",
    "            val_accuracy_epoch.append(val_accuracy_)\n",
    "            epoch_loss=np.mean(val_loss_array)\n",
    "            val_loss_array=[]\n",
    "            val_loss_epoch.append(epoch_loss)\n",
    "            print(val_loss_epoch)\n",
    "            print(val_accuracy_epoch)\n",
    "            \n",
    "            save_network(net)\n",
    "\n",
    "    return net, train_loss_epoch, train_accuracy_epoch, val_loss_epoch, val_accuracy_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_model(net,path):   \n",
    "        model = Net()\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(model,test_set):\n",
    "    tar=[]\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion=nn.CrossEntropyLoss() \n",
    "    predicted=[]\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "    \n",
    "            data = data.view(-1, img_Resize * img_Resize*1)\n",
    "            net_out = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(net_out, target).item()\n",
    "            pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "            p=pred.tolist()\n",
    "            t=target.tolist()\n",
    "            predicted=predicted+p\n",
    "            tar=tar+t\n",
    "            correct += pred.eq(target.data).sum()\n",
    "    \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "        examples = enumerate(test_loader)\n",
    "        batch_idx, (example_data, example_targets) = next(examples)\n",
    "        \n",
    "        fig1 = plt.figure()\n",
    "        for i in range(6):\n",
    "          plt.subplot(2,3,i+1)\n",
    "          plt.tight_layout()\n",
    "          plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "          plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "          plt.xticks([])\n",
    "          plt.yticks([])\n",
    "        fig1\n",
    "\n",
    "    return predicted, tar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize(pred,target,train_loss=None,train_Acc=None,Val_loss=None,Val_Acc=None):\n",
    "    \n",
    "\n",
    "    f1=f1_score(target, pred,average=None)\n",
    "    f1=sum(f1)/len(f1)\n",
    "    print(f1)\n",
    "    cm=confusion_matrix(target, pred)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in \"0123456789\"],\n",
    "                  columns = [i for i in \"0123456789\"])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True, linewidths=.5,fmt=\"d\")\n",
    "    \n",
    "\n",
    "    plt.title('Confusion Matrix', fontsize = 20) # title with fontsize 20\n",
    "    plt.xlabel('Predicted Labels', fontsize = 15) # x-axis label with fontsize 15\n",
    "    plt.ylabel('True Labels', fontsize = 15) # y-axis label with fontsize 15\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    if train_loss != None:\n",
    "        x1= Val_Acc\n",
    "        x2= train_Acc\n",
    "        x=[1,2,3,4,5,6,7,8,9,10]\n",
    "        plt.plot(x, x1, label = \"val_acc\")\n",
    "        plt.plot(x, x2, label = \"train_acc\" )\n",
    "        plt.title('Accuracy Comparison', fontsize=15)\n",
    "        plt.xlabel('Number of Epochs', fontsize=15)\n",
    "        plt.ylabel('Accuracy %', fontsize=15)\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show() \n",
    "\n",
    "        # plot lines \n",
    "        x1= Val_loss\n",
    "        x2= train_loss\n",
    "        x=[1,2,3,4,5,6,7,8,9,10]\n",
    "        # plot lines\n",
    "        plt.plot(x, x1, label = \"val_loss\")\n",
    "        plt.plot(x, x2, label = \"train_loss\" )\n",
    "        plt.title('Loss Comparison', fontsize=15)\n",
    "        plt.xlabel('Number of Epochs', fontsize=15)\n",
    "        plt.ylabel('Loss', fontsize=15)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show() \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(data_dir,size_train,size_val,size_test,Batch_Size,hidden,neural_list,isGPU,dropout,\n",
    "         is_Train,Visualizer,trainEpochs,Loss_func,\n",
    "         optimizer_,learning_rate_):\n",
    "    \n",
    "    img_Resize=28\n",
    "    t_loader,v_loader,test_loader=loadDataset(data_dir, size_train, size_val, size_test, Batch_Size,Shuffle=True)\n",
    "    A,B,C,D=init_network(hidden,img_Resize*img_Resize,neural_list,dropout )\n",
    "    class Net(nn.Module):\n",
    "    \n",
    "        def __init__(self, input_dim=A, output_dim=B, hidden_dim=C,droup_out=D):\n",
    "            super(Net, self).__init__()\n",
    "            self.input_dim = input_dim\n",
    "            self.output_dim = output_dim\n",
    "            self.hidden_dim = hidden_dim\n",
    "            current_dim = input_dim\n",
    "            self.layers = nn.ModuleList()\n",
    "            for hdim in hidden_dim:\n",
    "                if(hdim==hidden_dim[-1]):\n",
    "                    self.layers.append(nn.Dropout(droup_out))\n",
    "                    self.layers.append(nn.Linear(current_dim, hdim))\n",
    "                    current_dim = hdim\n",
    "\n",
    "                else:\n",
    "                    self.layers.append(nn.Linear(current_dim, hdim))\n",
    "                    current_dim = hdim\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            for layer in self.layers[:-1]:\n",
    "                x = F.leaky_relu(layer(x))\n",
    "            out = F.softmax(self.layers[-1](x))\n",
    "            \n",
    "            return out \n",
    "    \n",
    "    model = Net()\n",
    "    print(model)\n",
    "    learning_rate=0.05\n",
    "    epochs=10\n",
    "    \n",
    "    if isGPU==True:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "    \n",
    "    if is_Train==True:\n",
    "        model,train_loss,train_acc,val_loss,val_acc = train(model, t_loader,v_loader, trainEpochs, nn.CrossEntropyLoss(), optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9))\n",
    "    else:\n",
    "        # this loads the saved model from give directory.\n",
    "        model = Net()\n",
    "        train_acc=[]\n",
    "        model.load_state_dict(torch.load('C:/Users/Abdullah/.spyder-py3/weights.pth'))\n",
    "        \n",
    "    pred,target=test(model,test_loader)\n",
    "    if Visualizer==True and len(train_acc)>0:\n",
    "        visualize(pred,target,train_loss,train_acc,val_loss,val_acc)\n",
    "    elif Visualizer==True:\n",
    "        visualize(pred,target)\n",
    "        \n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdullah Aziz MSDS20052\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c1993ab3d321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mLoss_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlearning_rate_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0moptimizer_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0misGPU\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir='C:/Users/Abdullah/.spyder-py3/MNIST_Data'\n",
    "print('Abdullah Aziz','MSDS20052')\n",
    "\n",
    "Loss_func=nn.CrossEntropyLoss()\n",
    "learning_rate_=0.5\n",
    "optimizer_=optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "isGPU=False\n",
    "dropout=0.1\n",
    "is_Train=True\n",
    "Visualizer=True\n",
    "trainEpochs=10\n",
    "\n",
    "\n",
    "main(data_dir,size_train,size_val,size_test,Batch_Size,hidden,neural_list,isGPU,dropout,is_Train,Visualizer,trainEpochs,\n",
    "     Loss_func,optimizer_,learning_rate_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdullah Aziz MSDS20052\n",
      "50000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data_dir='C:/Users/Abdullah/.spyder-py3/MNIST_Data'\n",
    "print('Abdullah Aziz','MSDS20052')\n",
    "Train_size=50000\n",
    "Val_size=10000\n",
    "Test_size=10000\n",
    "batch_=64\n",
    "hidden=2\n",
    "neural_list=[100, 50,10]\n",
    "img_Resize=28\n",
    "\n",
    "\n",
    "_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),transforms.Resize((img_Resize,img_Resize)),transforms.ToTensor(),\n",
    "                                       transforms.Normalize(0.1307,0.3081)])\n",
    "\n",
    "data_train = datasets.ImageFolder((data_dir + '/' + 'train') , transform=_transforms)\n",
    "data_test=datasets.ImageFolder((data_dir+'/'+'test'), transform=_transforms)\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(data_train, [Train_size, Val_size])\n",
    "\n",
    "test_size=list(range(0, Test_size))\n",
    "\n",
    "\n",
    "test_data=torch.utils.data.Subset(data_test,test_size)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=0.1\n",
    "C=[100, 50,10]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=784, output_dim=C[-1], hidden_dim=C,droup_out=D):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        current_dim = input_dim\n",
    "        self.layers = nn.ModuleList()\n",
    "        for hdim in hidden_dim:\n",
    "            if(hdim==hidden_dim[-1]):\n",
    "                self.layers.append(nn.Dropout(droup_out))\n",
    "                self.layers.append(nn.Linear(current_dim, hdim))\n",
    "                current_dim = hdim\n",
    "                \n",
    "            else:\n",
    "                self.layers.append(nn.Linear(current_dim, hdim))\n",
    "                current_dim = hdim\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.leaky_relu(layer(x))\n",
    "        out = F.softmax(self.layers[-1](x))\n",
    "        return out   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-8b079b529ddd>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = F.softmax(self.layers[-1](x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.302569\n",
      "Train Epoch: 0 [640/50000 (1%)]\tLoss: 2.304336\n",
      "Train Epoch: 0 [1280/50000 (3%)]\tLoss: 2.302072\n",
      "Train Epoch: 0 [1920/50000 (4%)]\tLoss: 2.303528\n",
      "Train Epoch: 0 [2560/50000 (5%)]\tLoss: 2.300338\n",
      "Train Epoch: 0 [3200/50000 (6%)]\tLoss: 2.304111\n",
      "Train Epoch: 0 [3840/50000 (8%)]\tLoss: 2.300156\n",
      "Train Epoch: 0 [4480/50000 (9%)]\tLoss: 2.304207\n",
      "Train Epoch: 0 [5120/50000 (10%)]\tLoss: 2.300815\n",
      "Train Epoch: 0 [5760/50000 (12%)]\tLoss: 2.298398\n",
      "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.300295\n",
      "Train Epoch: 0 [7040/50000 (14%)]\tLoss: 2.300983\n",
      "Train Epoch: 0 [7680/50000 (15%)]\tLoss: 2.298836\n",
      "Train Epoch: 0 [8320/50000 (17%)]\tLoss: 2.301413\n",
      "Train Epoch: 0 [8960/50000 (18%)]\tLoss: 2.300502\n",
      "Train Epoch: 0 [9600/50000 (19%)]\tLoss: 2.302307\n",
      "Train Epoch: 0 [10240/50000 (20%)]\tLoss: 2.299599\n",
      "Train Epoch: 0 [10880/50000 (22%)]\tLoss: 2.301039\n",
      "Train Epoch: 0 [11520/50000 (23%)]\tLoss: 2.299074\n",
      "Train Epoch: 0 [12160/50000 (24%)]\tLoss: 2.296423\n",
      "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 2.298636\n",
      "Train Epoch: 0 [13440/50000 (27%)]\tLoss: 2.294931\n",
      "Train Epoch: 0 [14080/50000 (28%)]\tLoss: 2.291850\n",
      "Train Epoch: 0 [14720/50000 (29%)]\tLoss: 2.293318\n",
      "Train Epoch: 0 [15360/50000 (31%)]\tLoss: 2.294545\n",
      "Train Epoch: 0 [16000/50000 (32%)]\tLoss: 2.293491\n",
      "Train Epoch: 0 [16640/50000 (33%)]\tLoss: 2.296198\n",
      "Train Epoch: 0 [17280/50000 (35%)]\tLoss: 2.300312\n",
      "Train Epoch: 0 [17920/50000 (36%)]\tLoss: 2.295163\n",
      "Train Epoch: 0 [18560/50000 (37%)]\tLoss: 2.298069\n",
      "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.293287\n",
      "Train Epoch: 0 [19840/50000 (40%)]\tLoss: 2.292897\n",
      "Train Epoch: 0 [20480/50000 (41%)]\tLoss: 2.287774\n",
      "Train Epoch: 0 [21120/50000 (42%)]\tLoss: 2.296846\n",
      "Train Epoch: 0 [21760/50000 (43%)]\tLoss: 2.294840\n",
      "Train Epoch: 0 [22400/50000 (45%)]\tLoss: 2.289657\n",
      "Train Epoch: 0 [23040/50000 (46%)]\tLoss: 2.295767\n",
      "Train Epoch: 0 [23680/50000 (47%)]\tLoss: 2.290269\n",
      "Train Epoch: 0 [24320/50000 (49%)]\tLoss: 2.296313\n",
      "Train Epoch: 0 [24960/50000 (50%)]\tLoss: 2.297483\n",
      "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 2.291209\n",
      "Train Epoch: 0 [26240/50000 (52%)]\tLoss: 2.286082\n",
      "Train Epoch: 0 [26880/50000 (54%)]\tLoss: 2.287480\n",
      "Train Epoch: 0 [27520/50000 (55%)]\tLoss: 2.289030\n",
      "Train Epoch: 0 [28160/50000 (56%)]\tLoss: 2.291355\n",
      "Train Epoch: 0 [28800/50000 (58%)]\tLoss: 2.286517\n",
      "Train Epoch: 0 [29440/50000 (59%)]\tLoss: 2.285925\n",
      "Train Epoch: 0 [30080/50000 (60%)]\tLoss: 2.291502\n",
      "Train Epoch: 0 [30720/50000 (61%)]\tLoss: 2.283151\n",
      "Train Epoch: 0 [31360/50000 (63%)]\tLoss: 2.282264\n",
      "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 2.281619\n",
      "Train Epoch: 0 [32640/50000 (65%)]\tLoss: 2.277643\n",
      "Train Epoch: 0 [33280/50000 (66%)]\tLoss: 2.279182\n",
      "Train Epoch: 0 [33920/50000 (68%)]\tLoss: 2.287369\n",
      "Train Epoch: 0 [34560/50000 (69%)]\tLoss: 2.279798\n",
      "Train Epoch: 0 [35200/50000 (70%)]\tLoss: 2.277480\n",
      "Train Epoch: 0 [35840/50000 (72%)]\tLoss: 2.276985\n",
      "Train Epoch: 0 [36480/50000 (73%)]\tLoss: 2.268368\n",
      "Train Epoch: 0 [37120/50000 (74%)]\tLoss: 2.285966\n",
      "Train Epoch: 0 [37760/50000 (75%)]\tLoss: 2.275965\n",
      "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 2.279313\n",
      "Train Epoch: 0 [39040/50000 (78%)]\tLoss: 2.275422\n",
      "Train Epoch: 0 [39680/50000 (79%)]\tLoss: 2.271193\n",
      "Train Epoch: 0 [40320/50000 (81%)]\tLoss: 2.273503\n",
      "Train Epoch: 0 [40960/50000 (82%)]\tLoss: 2.261312\n",
      "Train Epoch: 0 [41600/50000 (83%)]\tLoss: 2.283581\n",
      "Train Epoch: 0 [42240/50000 (84%)]\tLoss: 2.264484\n",
      "Train Epoch: 0 [42880/50000 (86%)]\tLoss: 2.263924\n",
      "Train Epoch: 0 [43520/50000 (87%)]\tLoss: 2.269410\n",
      "Train Epoch: 0 [44160/50000 (88%)]\tLoss: 2.266730\n",
      "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 2.252839\n",
      "Train Epoch: 0 [45440/50000 (91%)]\tLoss: 2.257837\n",
      "Train Epoch: 0 [46080/50000 (92%)]\tLoss: 2.270683\n",
      "Train Epoch: 0 [46720/50000 (93%)]\tLoss: 2.257242\n",
      "Train Epoch: 0 [47360/50000 (95%)]\tLoss: 2.252326\n",
      "Train Epoch: 0 [48000/50000 (96%)]\tLoss: 2.239956\n",
      "Train Epoch: 0 [48640/50000 (97%)]\tLoss: 2.225537\n",
      "Train Epoch: 0 [49280/50000 (98%)]\tLoss: 2.251636\n",
      "Train Epoch: 0 [49920/50000 (100%)]\tLoss: 2.212029\n",
      "[2.2848923447765883]\n",
      "[25.577999114990234]\n",
      "Val Epoch: 0 [0/10000 (0%)]\tLoss: 2.247135\n",
      "Val Epoch: 0 [640/10000 (6%)]\tLoss: 2.252424\n",
      "Val Epoch: 0 [1280/10000 (13%)]\tLoss: 2.241668\n",
      "Val Epoch: 0 [1920/10000 (19%)]\tLoss: 2.230716\n",
      "Val Epoch: 0 [2560/10000 (25%)]\tLoss: 2.221981\n",
      "Val Epoch: 0 [3200/10000 (32%)]\tLoss: 2.229276\n",
      "Val Epoch: 0 [3840/10000 (38%)]\tLoss: 2.183084\n",
      "Val Epoch: 0 [4480/10000 (45%)]\tLoss: 2.253721\n",
      "Val Epoch: 0 [5120/10000 (51%)]\tLoss: 2.242380\n",
      "Val Epoch: 0 [5760/10000 (57%)]\tLoss: 2.268212\n",
      "Val Epoch: 0 [6400/10000 (64%)]\tLoss: 2.238349\n",
      "Val Epoch: 0 [7040/10000 (70%)]\tLoss: 2.244766\n",
      "Val Epoch: 0 [7680/10000 (76%)]\tLoss: 2.248973\n",
      "Val Epoch: 0 [8320/10000 (83%)]\tLoss: 2.233732\n",
      "Val Epoch: 0 [8960/10000 (89%)]\tLoss: 2.225206\n",
      "Val Epoch: 0 [9600/10000 (96%)]\tLoss: 2.233233\n",
      "[2.237178474664688]\n",
      "[33.79999923706055]\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.243056\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 2.241792\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.223598\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 2.241058\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.213671\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.224208\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2.222647\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 2.212691\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.224783\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 2.228637\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.209494\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 2.192284\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 2.135417\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 2.183216\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 2.168841\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.210907\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 2.203870\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 2.236157\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 2.206527\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 2.127460\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.166402\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 2.156269\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 2.200251\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 2.164722\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 2.167622\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.200382\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 2.181332\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 2.158235\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 2.225855\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 2.153642\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.153618\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 2.176177\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 2.142249\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 2.198847\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 2.121567\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 2.088770\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 2.093483\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 2.027606\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 2.150704\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 2.160532\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.137840\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 2.130957\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 2.138226\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 2.048584\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 2.057635\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 2.030644\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 2.073461\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 2.058921\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 2.055604\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 2.073910\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.042046\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 2.063072\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 2.058957\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.987793\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 2.083915\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.981224\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 2.006753\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 2.000739\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 2.009477\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 2.038208\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.978314\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 1.999793\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 2.003526\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 1.976643\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.944900\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.946428\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.984446\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 1.958252\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.968937\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 1.958596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.968367\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 1.972341\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 2.003456\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 1.903667\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 1.880410\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.012703\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 2.008346\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 1.930649\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.893036\n",
      "[2.2848923447765883, 2.096320918843716]\n",
      "[25.577999114990234, 47.89400100708008]\n",
      "Val Epoch: 1 [0/10000 (0%)]\tLoss: 1.972398\n",
      "Val Epoch: 1 [640/10000 (6%)]\tLoss: 1.934266\n",
      "Val Epoch: 1 [1280/10000 (13%)]\tLoss: 1.914585\n",
      "Val Epoch: 1 [1920/10000 (19%)]\tLoss: 1.844798\n",
      "Val Epoch: 1 [2560/10000 (25%)]\tLoss: 1.844449\n",
      "Val Epoch: 1 [3200/10000 (32%)]\tLoss: 1.884656\n",
      "Val Epoch: 1 [3840/10000 (38%)]\tLoss: 1.984246\n",
      "Val Epoch: 1 [4480/10000 (45%)]\tLoss: 1.878670\n",
      "Val Epoch: 1 [5120/10000 (51%)]\tLoss: 1.856087\n",
      "Val Epoch: 1 [5760/10000 (57%)]\tLoss: 1.909438\n",
      "Val Epoch: 1 [6400/10000 (64%)]\tLoss: 1.931241\n",
      "Val Epoch: 1 [7040/10000 (70%)]\tLoss: 1.945917\n",
      "Val Epoch: 1 [7680/10000 (76%)]\tLoss: 1.965763\n",
      "Val Epoch: 1 [8320/10000 (83%)]\tLoss: 1.871901\n",
      "Val Epoch: 1 [8960/10000 (89%)]\tLoss: 1.922328\n",
      "Val Epoch: 1 [9600/10000 (96%)]\tLoss: 1.930780\n",
      "[2.237178474664688, 1.9119702279567719]\n",
      "[33.79999923706055, 62.15999984741211]\n"
     ]
    }
   ],
   "source": [
    "train_loss_array=[]\n",
    "train_loss_epoch=[]\n",
    "train_accuracy_epoch=[]\n",
    "val_loss_array=[]\n",
    "val_loss_epoch=[]\n",
    "val_accuracy_epoch=[]\n",
    "training_epochs=2\n",
    "criterion=nn.CrossEntropyLoss() \n",
    "device='cpu'\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)        \n",
    "        data = data.view(-1, img_Resize*img_Resize*1)\n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(data)\n",
    "        pred = net_out.data.max(1)[1] \n",
    "        loss = criterion(net_out, target)\n",
    "        correct += pred.eq(target.data).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_loss_array.append(loss.item())\n",
    "\n",
    "    train_accuracy_=float(100 * correct / len(train_loader.dataset))\n",
    "    train_accuracy_epoch.append(train_accuracy_)\n",
    "    epoch_loss=np.mean(train_loss_array)\n",
    "    train_loss_array=[]\n",
    "    train_loss_epoch.append(epoch_loss)\n",
    "    print(train_loss_epoch)\n",
    "    print(train_accuracy_epoch)\n",
    "\n",
    "    correct=0\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)        \n",
    "            data = data.view(-1, img_Resize*img_Resize*1)\n",
    "            net_out = net(data)\n",
    "            pred = net_out.data.max(1)[1]\n",
    "\n",
    "            loss = criterion(net_out, target)\n",
    "            correct += pred.eq(target.data).sum()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Val Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(val_loader.dataset),\n",
    "                               100. * batch_idx / len(val_loader), loss.item()))\n",
    "                val_loss_array.append(loss.item())\n",
    "\n",
    "        val_accuracy_=float(100 * correct / len(val_loader.dataset))\n",
    "        val_accuracy_epoch.append(val_accuracy_)\n",
    "        epoch_loss=np.mean(val_loss_array)\n",
    "        val_loss_array=[]\n",
    "        val_loss_epoch.append(epoch_loss)\n",
    "        print(val_loss_epoch)\n",
    "        print(val_accuracy_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdullah\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
